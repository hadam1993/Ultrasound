{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import functools\n",
    "import itertools\n",
    "from utils import ReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(image_size=256, batch_size=1, num_workers=0):\n",
    "    \"\"\"\n",
    "    Returns training and test data loaders for a given image\n",
    "    type, either 'low frequency' or 'high frequency'. \n",
    "    These images will be resized to image_sizeximage_sizex1,\n",
    "    by default, converted into Tensors, and normalized.\n",
    "    \"\"\"\n",
    "    #transforms.RandomCrop((image_size/2,image_size)),\n",
    "    # crop and normalize the images\n",
    "    transform = transforms.Compose([transforms.Grayscale(),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.5,], [0.5,])])\n",
    "    test_transform = transforms.Compose([transforms.Grayscale(),\n",
    "                                         transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.5,], [0.5,])])\n",
    "\n",
    "    # get training and test directories\n",
    "    train_A_path = '/home/ahonts/Desktop/US/Low_Images'\n",
    "    test_A_path = '/home/ahonts/Desktop/US/Low_Images'\n",
    "    train_B_path = '/home/ahonts/Desktop/US/High_Images'\n",
    "    test_B_path = '/home/ahonts/Desktop/US/High_Images'\n",
    "\n",
    "    # define datasets using ImageFolder\n",
    "    train_A_dataset = datasets.ImageFolder(train_A_path, transform)\n",
    "    test_A_dataset = datasets.ImageFolder(test_A_path, test_transform)\n",
    "    train_B_dataset = datasets.ImageFolder(train_B_path, transform)\n",
    "    test_B_dataset = datasets.ImageFolder(test_B_path, test_transform)\n",
    "\n",
    "    # create DataLoaders\n",
    "    train_A_loader = DataLoader(dataset=train_A_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    test_A_loader = DataLoader(dataset=test_A_dataset, batch_size=1, shuffle=False, num_workers=num_workers)\n",
    "    train_B_loader = DataLoader(dataset=train_B_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    test_B_loader = DataLoader(dataset=test_B_dataset, batch_size=1, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    #return DataLoaders\n",
    "    return train_A_loader,test_A_loader,train_B_loader,test_B_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_A_loader,test_A_loader,train_B_loader,test_B_loader = get_data_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator2, self).__init__()\n",
    "        self.d1 = nn.Conv2d(1, 32, 8, 2, 3, bias=False)\n",
    "        self.d2 = nn.Conv2d(32, 64, 8, 2, 3, bias=False)\n",
    "        self.d3 = nn.Conv2d(64, 128, 8, 2, 3, bias=False)\n",
    "        self.d4 = nn.Conv2d(128, 256, 8, 2, 3, bias=False)\n",
    "        self.d5 = nn.Conv2d(256, 512, 8, 2, 3, bias=False)\n",
    "        self.d1_1 = nn.Conv2d(1, 32, 4, 2, 1, bias=False)\n",
    "        self.d2_1 = nn.Conv2d(32, 64, 4, 2, 1, bias=False)\n",
    "        self.d3_1 = nn.Conv2d(64, 128, 4, 2, 1, bias=False)\n",
    "        self.d4_1 = nn.Conv2d(128, 256, 4, 2, 1, bias=False)\n",
    "        #self.d5_1 = nn.Conv2d(256, 512, 4, 2, 1, bias=False)\n",
    "        self.u1 = nn.ConvTranspose2d(512, 256, 8, 2, 3, bias=False)\n",
    "        #self.u2 = nn.ConvTranspose2d(512, 128, 8, 2, 3, bias=False)\n",
    "        self.u2 = nn.ConvTranspose2d(768, 128, 8, 2, 3, bias=False)\n",
    "        #self.u3 = nn.ConvTranspose2d(256, 64, 8, 2, 3, bias=False)\n",
    "        self.u3 = nn.ConvTranspose2d(384, 64, 8, 2, 3, bias=False)\n",
    "        #self.u4 = nn.ConvTranspose2d(128, 32, 8, 2, 3, bias=False)\n",
    "        self.u4 = nn.ConvTranspose2d(192, 32, 8, 2, 3, bias=False)\n",
    "        #self.u5 = nn.ConvTranspose2d(64, 64, 8, 2, 3, bias=False)\n",
    "        self.u5 = nn.ConvTranspose2d(96, 64, 8, 2, 3, bias=False)\n",
    "        self.out = nn.Conv2d(64, 1, 3, 1, 1, bias=False)\n",
    "        self.LeakyRelu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.Relu = nn.ReLU(True)\n",
    "        self.d1Norm = nn.InstanceNorm2d(32)\n",
    "        self.d2Norm = nn.InstanceNorm2d(64)\n",
    "        self.d3Norm = nn.InstanceNorm2d(128)\n",
    "        self.d4Norm = nn.InstanceNorm2d(256)\n",
    "        self.d5Norm = nn.InstanceNorm2d(512)\n",
    "\n",
    "    def forward(self, input):\n",
    "        d1 = self.d1(input)\n",
    "        d1 = self.LeakyRelu(d1)\n",
    "        d1 = self.d1Norm(d1)\n",
    "        \n",
    "        d1_1 = self.d1_1(input)\n",
    "        d1_1 = self.LeakyRelu(d1_1)\n",
    "        d1_1 = self.d1Norm(d1_1)\n",
    "        \n",
    "        d2 = self.d2(d1)\n",
    "        d2 = self.LeakyRelu(d2)\n",
    "        d2 = self.d2Norm(d2)\n",
    "        \n",
    "        d2_1 = self.d2_1(d1_1)\n",
    "        d2_1 = self.LeakyRelu(d2_1)\n",
    "        d2_1 = self.d2Norm(d2_1)\n",
    "        \n",
    "        d3 = self.d3(d2)\n",
    "        d3 = self.LeakyRelu(d3)\n",
    "        d3 = self.d3Norm(d3)\n",
    "        \n",
    "        d3_1 = self.d3_1(d2_1)\n",
    "        d3_1 = self.LeakyRelu(d3_1)\n",
    "        d3_1 = self.d3Norm(d3_1)\n",
    "        \n",
    "        d4 = self.d4(d3)\n",
    "        d4 = self.LeakyRelu(d4)\n",
    "        d4 = self.d4Norm(d4)\n",
    "        \n",
    "        d4_1 = self.d4_1(d3_1)\n",
    "        d4_1 = self.LeakyRelu(d4_1)\n",
    "        d4_1 = self.d4Norm(d4_1)\n",
    "        \n",
    "        d5 = self.d5(d4)\n",
    "        d5 = self.LeakyRelu(d5)\n",
    "        d5 = self.d5Norm(d5)\n",
    "        \n",
    "        u1 = self.u1(d5)\n",
    "        u1 = self.Relu(u1)\n",
    "        u1 = self.d4Norm(u1)\n",
    "        u1 = torch.cat([u1, d4, d4_1],1)\n",
    "        \n",
    "        u2 = self.u2(u1)\n",
    "        u2 = self.Relu(u2)\n",
    "        u2 = self.d3Norm(u2)\n",
    "        u2 = torch.cat([u2, d3, d3_1],1)\n",
    "        \n",
    "        u3 = self.u3(u2)\n",
    "        u3 = self.Relu(u3)\n",
    "        u3 = self.d2Norm(u3)\n",
    "        u3 = torch.cat([u3, d2, d2_1],1)\n",
    "        \n",
    "        u4 = self.u4(u3)\n",
    "        u4 = self.Relu(u4)\n",
    "        u4 = self.d1Norm(u4)\n",
    "        u4 = torch.cat([u4, d1, d1_1],1)\n",
    "        \n",
    "        u5 = self.u5(u4)\n",
    "        output = self.out(u5)\n",
    "        output = torch.tanh(output)\n",
    "        \n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_A_loader,test_A_loader,train_B_loader,test_B_loader = get_data_loader()\n",
    "train_A_loader_iterator = iter(train_A_loader)\n",
    "train_B_loader_iterator = iter(train_B_loader)\n",
    "test_A_loader_iterator = iter(test_A_loader)\n",
    "real_A, _ = train_A_loader_iterator.next()\n",
    "real_B, _ = train_B_loader_iterator.next()\n",
    "test_A, _ = test_A_loader_iterator.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need To test how to apply the filter to the whole image. The Test image contains the whole image while the train images only contain the filter size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "to_pil = torchvision.transforms.ToPILImage()\n",
    "imgs = real_A_imgs.squeeze()\n",
    "test_A *= 0.5\n",
    "test_A += 0.5\n",
    "img = to_pil(test_A)\n",
    "plt.imshow(img,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_image(img,G,crop_h = 128,crop_w = 256):\n",
    "    height,width = img.shape[2],img.shape[3]\n",
    "    avg_cnt = np.zeros((height,width))\n",
    "    ones_cnt = np.ones((crop_h,crop_w))\n",
    "    comp_img = np.zeros((height,width))\n",
    "    row_index = 0\n",
    "    while row_index < height-crop_h:\n",
    "        column_index = 0\n",
    "        while column_index < width-crop_w:\n",
    "            tmp = G(img[:,:,\n",
    "                        row_index:row_index+crop_h,\n",
    "                        column_index:column_index+crop_w]).detach().cpu().numpy()[0,0,:,:]\n",
    "            comp_img[row_index:row_index+crop_h,column_index:column_index+crop_w] += tmp\n",
    "            avg_cnt[row_index:row_index+crop_h,column_index:column_index+crop_w] += ones_cnt\n",
    "            column_index += int(np.floor(crop_w/19))\n",
    "        comp_img[row_index:row_index+crop_h,-crop_w:] += G(img[:,:,\n",
    "                                                    row_index:row_index+crop_h,\n",
    "                                                    -crop_w:]).detach().cpu().numpy()[0,0,:,:]\n",
    "        avg_cnt[row_index:row_index+crop_h,-crop_w:] += ones_cnt\n",
    "        row_index += int(np.floor(crop_h/19))\n",
    "    column_index = 0\n",
    "    row_index = height - crop_h\n",
    "    while column_index < width-crop_w:\n",
    "        comp_img[row_index:row_index+crop_h, column_index:column_index+crop_w] += G(img[:,:,\n",
    "                                                    row_index:row_index+crop_h,\n",
    "                                                     column_index:column_index+crop_w]).detach().cpu().numpy()[0,0,:,:]\n",
    "        avg_cnt[row_index:row_index+crop_h,column_index:column_index+crop_w] += ones_cnt\n",
    "        column_index += int(np.floor(crop_w/19))\n",
    "    comp_img[row_index:row_index+crop_h, -crop_w:] += G(img[:,:,\n",
    "                                                    row_index:row_index+crop_h,\n",
    "                                                     -crop_w:]).detach().cpu().numpy()[0,0,:,:]\n",
    "    avg_cnt[row_index:row_index+crop_h,-crop_w:] += ones_cnt\n",
    "    return(comp_img/avg_cnt)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 8, 2, 3, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(64, 64*2, 8, 2, 3, bias=False),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # input is 64 x 64\n",
    "            nn.Conv2d(64*2, 64*4, 8, 2, 3, bias=False),\n",
    "            nn.InstanceNorm2d(64 * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (64) x 32 x 32\n",
    "            nn.Conv2d(64*4, 64 * 4, 8, 2, 3, bias=False),\n",
    "            nn.InstanceNorm2d(64 * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (64*2) x 16 x 16\n",
    "            nn.Conv2d(64*4, 64 * 8, 8, 2, 3, bias=False),\n",
    "            nn.InstanceNorm2d(64 * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(64 * 8, 1, 3, 1, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator2, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 8, 2, 3, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(64, 64*2, 8, 2, 3, bias=False),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # input is 64 x 64\n",
    "            nn.Conv2d(64*2, 64*4, 8, 2, 3, bias=False),\n",
    "            nn.InstanceNorm2d(64 * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (64) x 32 x 32\n",
    "            nn.Conv2d(64*4, 64 * 4, 8, 2, 3, bias=False),\n",
    "            nn.InstanceNorm2d(64 * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (64*2) x 16 x 16\n",
    "            nn.Conv2d(64*4, 64 * 8, 8, 2, 3, bias=False),\n",
    "            nn.InstanceNorm2d(64 * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            #nn.Conv2d(64 * 8, 1, 3, 1, 1, bias=False),\n",
    "            #nn.Sigmoid()\n",
    "        )\n",
    "        self.fc1 = nn.Linear(16384,1000)\n",
    "        self.fc2 = nn.Linear(1000,1)\n",
    "        self.Lrelu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.Lrelu(self.fc1(output))\n",
    "        output = self.sigmoid(self.fc2(output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#Create the Generator Network\n",
    "G_AB = Generator2()\n",
    "G_BA = Generator2()\n",
    "#Load Generator Network onto the GPU\n",
    "G_AB.to(device)\n",
    "G_BA.to(device)\n",
    "#Apply weights to the Generator\n",
    "G_AB.apply(weights_init)\n",
    "G_BA.apply(weights_init)\n",
    "#Create the Discriminator Network\n",
    "D_A = Discriminator2()\n",
    "D_B = Discriminator2()\n",
    "#Load the Disriminator Network onto the GPU\n",
    "D_A.to(device)\n",
    "D_B.to(device)\n",
    "#Apply weights to the Discriminator\n",
    "D_A.apply(weights_init)\n",
    "D_B.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "#Create Optimizers\n",
    "optimizer_G = torch.optim.Adam(itertools.chain(G_AB.parameters(), G_BA.parameters()),\n",
    "                                lr=0.0002, betas=(0.5, 0.999))\n",
    "#Optimizer_G_AB = optim.Adam(G_AB.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "#Optimizer_G_BA = optim.Adam(G_BA.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D_A = optim.Adam(D_A.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D_B = optim.Adam(D_B.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "adversarial_loss = nn.BCELoss()\n",
    "cycle_consis_loss = nn.L1Loss()\n",
    "identity_loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_A_loader,test_A_loader,train_B_loader,test_B_loader = get_data_loader()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "fake_A_buffer = ReplayBuffer()\n",
    "fake_B_buffer = ReplayBuffer()\n",
    "criterion_GAN = torch.nn.BCELoss()\n",
    "criterion_cycle = torch.nn.L1Loss()\n",
    "criterion_identity = torch.nn.L1Loss()\n",
    "test_A_loader_iterator = iter(test_A_loader)\n",
    "test_B_loader_iterator = iter(test_B_loader)\n",
    "test_real_A, _ = test_A_loader_iterator.next()\n",
    "test_real_B, _ = test_B_loader_iterator.next()\n",
    "test_real_A = test_real_A.to(device)\n",
    "test_real_B = test_real_B.to(device)\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "target_real = torch.full((1,), real_label, device=device)\n",
    "target_fake = torch.full((1,), fake_label, device=device)\n",
    "for epoch in range(11,50):\n",
    "    train_A_loader_iterator = iter(train_A_loader)\n",
    "    train_B_loader_iterator = iter(train_B_loader)\n",
    "    brake = False\n",
    "    print(epoch)\n",
    "    for cnt in range(1000):\n",
    "        #target_real = torch.full((1,1,2,8), np.random.uniform(.95,1.05), device=device)\n",
    "        #target_fake = torch.full((1,1,2,8), np.random.uniform(-0.05,.05), device=device)\n",
    "        try:\n",
    "            real_A, _ = train_A_loader_iterator.next()\n",
    "            real_B, _ = train_B_loader_iterator.next()\n",
    "            h_A = real_A.shape[2]\n",
    "            h_B = real_B.shape[2]\n",
    "            w_A = real_A.shape[3]\n",
    "            w_B = real_B.shape[3]\n",
    "            rand_h_A = random.randint(0,h_A - 129)\n",
    "            rand_w_A = random.randint(0,w_A - 257)\n",
    "            real_A = real_A[:,:,rand_h_A:rand_h_A+128,rand_w_A:rand_w_A+256]\n",
    "            rand_h_B = random.randint(0,int(h_B/6))\n",
    "            rand_w_B = random.randint(0,w_B - 257)\n",
    "            real_B = real_B[:,:,rand_h_B:rand_h_B+128,rand_w_B:rand_w_B+256]\n",
    "            #real_A = real_A[:,:,64:192,:]\n",
    "            #real_B = real_B[:,:,64:192,:]\n",
    "            real_A = real_A.to(device)\n",
    "            real_B = real_B.to(device)\n",
    "        except:\n",
    "            brake = True\n",
    "            break\n",
    "        if cnt%100 == 0:\n",
    "            print(cnt)\n",
    "        ###### Generators A2B and B2A ######\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Identity loss\n",
    "        # G_A2B(B) should equal B if real B is fed\n",
    "        same_B = G_AB(real_B)\n",
    "        loss_identity_B = criterion_identity(same_B, real_B)*10.0\n",
    "        # G_B2A(A) should equal A if real A is fed\n",
    "        same_A = G_BA(real_A)\n",
    "        loss_identity_A = criterion_identity(same_A, real_A)*10.0\n",
    "\n",
    "        # GAN loss\n",
    "        fake_B = G_AB(real_A)\n",
    "        pred_fake = D_B(fake_B)\n",
    "        loss_GAN_A2B = criterion_GAN(pred_fake, target_real)\n",
    "\n",
    "        fake_A = G_BA(real_B)\n",
    "        pred_fake = D_A(fake_A)\n",
    "        loss_GAN_B2A = criterion_GAN(pred_fake, target_real)\n",
    "\n",
    "        # Cycle loss\n",
    "        recovered_A = G_BA(fake_B)\n",
    "        loss_cycle_ABA = criterion_cycle(recovered_A, real_A)*10.0\n",
    "\n",
    "        recovered_B = G_AB(fake_A)\n",
    "        loss_cycle_BAB = criterion_cycle(recovered_B, real_B)*10.0\n",
    "        \n",
    "        #MINE Loss\n",
    "        retAB = torch.mean(real_B) - torch.log(torch.mean(torch.exp(fake_B)))\n",
    "        retBA = torch.mean(real_A) - torch.log(torch.mean(torch.exp(fake_A)))\n",
    "\n",
    "        # Total loss\n",
    "        loss_G = loss_identity_A + loss_identity_B + loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB - retAB - retBA\n",
    "        loss_G.backward()\n",
    "        \n",
    "        optimizer_G.step()\n",
    "        ###################################\n",
    "        for i in range(2):\n",
    "            try:\n",
    "                real_A, _ = train_A_loader_iterator.next()\n",
    "                real_B, _ = train_B_loader_iterator.next()\n",
    "                h_A = real_A.shape[2]\n",
    "                h_B = real_B.shape[2]\n",
    "                w_A = real_A.shape[3]\n",
    "                w_B = real_B.shape[3]\n",
    "                rand_h_A = random.randint(0,h_A - 129)\n",
    "                rand_w_A = random.randint(0,w_A - 257)\n",
    "                real_A = real_A[:,:,rand_h_A:rand_h_A+128,rand_w_A:rand_w_A+256]\n",
    "                rand_h_B = random.randint(0,int(h_B/6))\n",
    "                rand_w_B = random.randint(0,w_B - 257)\n",
    "                real_B = real_B[:,:,rand_h_B:rand_h_B+128,rand_w_B:rand_w_B+256]\n",
    "                #real_A = real_A[:,:,64:192,:]\n",
    "                #real_B = real_B[:,:,64:192,:]\n",
    "                real_A = real_A.to(device)\n",
    "                real_B = real_B.to(device)\n",
    "            except:\n",
    "                brake = True\n",
    "                break\n",
    "            ###### Discriminator A ######\n",
    "            #target_real = torch.full((1,1,2,8), np.random.uniform(.95,1.05), device=device)\n",
    "            #target_fake = torch.full((1,1,2,8), np.random.uniform(-0.05,.05), device=device)\n",
    "            optimizer_D_A.zero_grad()\n",
    "\n",
    "            # Real loss\n",
    "            pred_real = D_A(real_A)\n",
    "            loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "\n",
    "            # Fake loss\n",
    "            fake_A = fake_A_buffer.push_and_pop(fake_A)\n",
    "            pred_fake = D_A(fake_A.detach())\n",
    "            loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "            # Total loss\n",
    "            loss_D_A = (loss_D_real + loss_D_fake)*0.5\n",
    "            loss_D_A.backward()\n",
    "\n",
    "            optimizer_D_A.step()\n",
    "            ###################################\n",
    "\n",
    "            ###### Discriminator B ######\n",
    "            optimizer_D_B.zero_grad()\n",
    "\n",
    "            # Real loss\n",
    "            pred_real = D_B(real_B)\n",
    "            loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "\n",
    "            # Fake loss\n",
    "            fake_B = fake_B_buffer.push_and_pop(fake_B)\n",
    "            pred_fake = D_B(fake_B.detach())\n",
    "            loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "            # Total loss\n",
    "            loss_D_B = (loss_D_real + loss_D_fake)*0.5\n",
    "            loss_D_B.backward()\n",
    "\n",
    "            optimizer_D_B.step()\n",
    "        ###################################\n",
    "    \n",
    "    torch.save(G_AB.state_dict(), './paths3/netG_A2B_%d.pth' % epoch)\n",
    "    torch.save(G_BA.state_dict(), './paths3/netG_B2A_%d.pth' % epoch)\n",
    "    torch.save(D_A.state_dict(), './paths3/netD_A_%d.pth' % epoch)\n",
    "    torch.save(D_B.state_dict(), './paths3/netD_B_%d.pth' % epoch)\n",
    "    \n",
    "    fake_imgs_B = filter_image(test_real_A,G_AB)\n",
    "    fake_imgs_B *= 0.5\n",
    "    fake_imgs_B += 0.5\n",
    "    tmp = torch.ones_like(test_real_A)\n",
    "    tmp *= test_real_A\n",
    "    tmp *= 0.5\n",
    "    tmp += 0.5\n",
    "    save_image(torch.tensor(fake_imgs_B),'./fake_imgs3/test%d.png' % epoch)\n",
    "    save_image(tmp,'./real_imgs3/test%d.png' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    test_real_A, _ = test_A_loader_iterator.next()\n",
    "    test_real_A = test_real_A.to(device)\n",
    "    epoch = 60\n",
    "    fake_imgs_B = filter_image(test_real_A,G_AB)\n",
    "    fake_imgs_B *= 0.5\n",
    "    fake_imgs_B += 0.5\n",
    "    tmp = torch.ones_like(test_real_A)\n",
    "    tmp *= test_real_A\n",
    "    tmp *= 0.5\n",
    "    tmp += 0.5\n",
    "    tmp2 = torch.ones_like(test_real_A)\n",
    "    tmp2 = 0.1*tmp.detach().cpu() + 0.9*torch.tensor(fake_imgs_B)\n",
    "    save_image(torch.tensor(tmp2),'./video2/test%d.png' % i)\n",
    "    #save_image(torch.tensor(fake_imgs_B),'./fake_imgs3/test%d.png' % epoch)\n",
    "    save_image(tmp,'./real_video2/test%d.png' % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fake_A_buffer = ReplayBuffer()\n",
    "fake_B_buffer = ReplayBuffer()\n",
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_cycle = torch.nn.L1Loss()\n",
    "criterion_identity = torch.nn.L1Loss()\n",
    "test_A_loader_iterator = iter(test_A_loader)\n",
    "test_B_loader_iterator = iter(test_B_loader)\n",
    "test_real_A, _ = test_A_loader_iterator.next()\n",
    "test_real_B, _ = test_B_loader_iterator.next()\n",
    "test_real_A = test_real_A.to(device)\n",
    "test_real_B = test_real_B.to(device)\n",
    "for epoch in range(12):\n",
    "    train_A_loader_iterator = iter(train_A_loader)\n",
    "    train_B_loader_iterator = iter(train_B_loader)\n",
    "    brake = False\n",
    "    print(epoch)\n",
    "    for cnt in range(1000):\n",
    "        target_real = torch.full((1,1,2,8), np.random.uniform(.95,1.05), device=device)\n",
    "        target_fake = torch.full((1,1,2,8), np.random.uniform(-0.05,.05), device=device)\n",
    "        try:\n",
    "            real_A, _ = train_A_loader_iterator.next()\n",
    "            real_B, _ = train_B_loader_iterator.next()\n",
    "            real_A = real_A[:,:,64:192,:]\n",
    "            real_B = real_B[:,:,64:192,:]\n",
    "            real_A = real_A.to(device)\n",
    "            real_B = real_B.to(device)\n",
    "        except:\n",
    "            brake = True\n",
    "            break\n",
    "        if cnt%100 == 0:\n",
    "            print(cnt)\n",
    "        ###### Generators A2B and B2A ######\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Identity loss\n",
    "        # G_A2B(B) should equal B if real B is fed\n",
    "        same_B = G_AB(real_B)\n",
    "        loss_identity_B = criterion_identity(same_B, real_B)*10.0\n",
    "        # G_B2A(A) should equal A if real A is fed\n",
    "        same_A = G_BA(real_A)\n",
    "        loss_identity_A = criterion_identity(same_A, real_A)*10.0\n",
    "\n",
    "        # GAN loss\n",
    "        fake_B = G_AB(real_A)\n",
    "        pred_fake = D_B(fake_B)\n",
    "        loss_GAN_A2B = criterion_GAN(pred_fake, target_real)\n",
    "\n",
    "        fake_A = G_BA(real_B)\n",
    "        pred_fake = D_A(fake_A)\n",
    "        loss_GAN_B2A = criterion_GAN(pred_fake, target_real)\n",
    "\n",
    "        # Cycle loss\n",
    "        recovered_A = G_BA(fake_B)\n",
    "        loss_cycle_ABA = criterion_cycle(recovered_A, real_A)*10.0\n",
    "\n",
    "        recovered_B = G_AB(fake_A)\n",
    "        loss_cycle_BAB = criterion_cycle(recovered_B, real_B)*10.0\n",
    "        \n",
    "        #MINE Loss\n",
    "        retAB = torch.mean(real_B) - torch.log(torch.mean(torch.exp(fake_B)))\n",
    "        retBA = torch.mean(real_A) - torch.log(torch.mean(torch.exp(fake_A)))\n",
    "\n",
    "        # Total loss\n",
    "        loss_G = loss_identity_A + loss_identity_B + loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB - retAB - retBA\n",
    "        loss_G.backward()\n",
    "        \n",
    "        optimizer_G.step()\n",
    "        ###################################\n",
    "        for i in range(2):\n",
    "            try:\n",
    "                real_A, _ = train_A_loader_iterator.next()\n",
    "                real_B, _ = train_B_loader_iterator.next()\n",
    "                #real_A = real_A[:,:,64:192,:]\n",
    "                #real_B = real_B[:,:,64:192,:]\n",
    "                real_A = real_A.to(device)\n",
    "                real_B = real_B.to(device)\n",
    "            except:\n",
    "                brake = True\n",
    "                break\n",
    "            ###### Discriminator A ######\n",
    "            target_real = torch.full((1,1,2,8), np.random.uniform(.95,1.05), device=device)\n",
    "            target_fake = torch.full((1,1,2,8), np.random.uniform(-0.05,.05), device=device)\n",
    "            optimizer_D_A.zero_grad()\n",
    "\n",
    "            # Real loss\n",
    "            pred_real = D_A(real_A)\n",
    "            loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "\n",
    "            # Fake loss\n",
    "            fake_A = fake_A_buffer.push_and_pop(fake_A)\n",
    "            pred_fake = D_A(fake_A.detach())\n",
    "            loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "            # Total loss\n",
    "            loss_D_A = (loss_D_real + loss_D_fake)*0.5\n",
    "            loss_D_A.backward()\n",
    "\n",
    "            optimizer_D_A.step()\n",
    "            ###################################\n",
    "\n",
    "            ###### Discriminator B ######\n",
    "            optimizer_D_B.zero_grad()\n",
    "\n",
    "            # Real loss\n",
    "            pred_real = D_B(real_B)\n",
    "            loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "\n",
    "            # Fake loss\n",
    "            fake_B = fake_B_buffer.push_and_pop(fake_B)\n",
    "            pred_fake = D_B(fake_B.detach())\n",
    "            loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "            # Total loss\n",
    "            loss_D_B = (loss_D_real + loss_D_fake)*0.5\n",
    "            loss_D_B.backward()\n",
    "\n",
    "            optimizer_D_B.step()\n",
    "        ###################################\n",
    "    \n",
    "    torch.save(G_AB.state_dict(), './paths/netG_A2B_%d.pth' % epoch)\n",
    "    torch.save(G_BA.state_dict(), './paths/netG_B2A_%d.pth' % epoch)\n",
    "    torch.save(D_A.state_dict(), './paths/netD_A_%d.pth' % epoch)\n",
    "    torch.save(D_B.state_dict(), './paths/netD_B_%d.pth' % epoch)\n",
    "    \n",
    "    fake_imgs_B = filter_image(test_real_A,G_AB)\n",
    "    fake_imgs_B *= 0.5\n",
    "    fake_imgs_B += 0.5\n",
    "    tmp = torch.ones_like(test_real_A)\n",
    "    tmp *= test_real_A\n",
    "    tmp *= 0.5\n",
    "    tmp += 0.5\n",
    "    save_image(torch.tensor(fake_imgs_B),'./fake_imgs/test%d.png' % epoch)\n",
    "    save_image(tmp,'./real_imgs/test%d.png' % epoch)\n",
    "    #save_image(fake_imgs_A.detach().cpu(),'C:/Users/ajhon/Desktop/Industrial Math Presentation/Low_freq_256_2/test%d.png' % epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
