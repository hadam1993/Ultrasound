{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import functools\n",
    "import itertools\n",
    "from utils import ReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(image_size=256, batch_size=1, num_workers=0):\n",
    "    \"\"\"Returns training and test data loaders for a given image type, either 'low frequency' or 'high frequency'. \n",
    "       These images will be resized to image_sizeximage_sizex1, by default, converted into Tensors, and normalized.\n",
    "    \"\"\"\n",
    "    \n",
    "    # crop and normalize the images\n",
    "    transform = transforms.Compose([transforms.Resize((image_size,image_size)),\n",
    "                                    transforms.Grayscale(),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.5,], [0.5,])])\n",
    "    test_transform = transforms.Compose([transforms.Resize((image_size,image_size)),\n",
    "                                         transforms.Grayscale(),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize([0.5,], [0.5,])])\n",
    "\n",
    "    # get training and test directories\n",
    "    train_A_path = 'C:/Users/ajhon/Desktop/US Frames/TrainingImages/lo'\n",
    "    test_A_path = 'C:/Users/ajhon/Desktop/US Frames/TrainingImages/low_test'\n",
    "    train_B_path = 'C:/Users/ajhon/Desktop/US Frames/TrainingImages/hi'\n",
    "    test_B_path = 'C:/Users/ajhon/Desktop/US Frames/TrainingImages/hi_test'\n",
    "\n",
    "    # define datasets using ImageFolder\n",
    "    train_A_dataset = datasets.ImageFolder(train_A_path, transform)\n",
    "    test_A_dataset = datasets.ImageFolder(test_A_path, test_transform)\n",
    "    train_B_dataset = datasets.ImageFolder(train_B_path, transform)\n",
    "    test_B_dataset = datasets.ImageFolder(test_B_path, test_transform)\n",
    "\n",
    "    # create DataLoaders\n",
    "    train_A_loader = DataLoader(dataset=train_A_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    test_A_loader = DataLoader(dataset=test_A_dataset, batch_size=8, shuffle=False, num_workers=num_workers)\n",
    "    train_B_loader = DataLoader(dataset=train_B_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    test_B_loader = DataLoader(dataset=test_B_dataset, batch_size=8, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    #return DataLoaders\n",
    "    return train_A_loader,test_A_loader,train_B_loader,test_B_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator2, self).__init__()\n",
    "        self.d1 = nn.Conv2d(1, 32, 8, 2, 3, bias=False)\n",
    "        self.d2 = nn.Conv2d(32, 64, 8, 2, 3, bias=False)\n",
    "        self.d3 = nn.Conv2d(64, 128, 8, 2, 3, bias=False)\n",
    "        self.d4 = nn.Conv2d(128, 256, 8, 2, 3, bias=False)\n",
    "        self.d5 = nn.Conv2d(256, 512, 8, 2, 3, bias=False)\n",
    "        self.d1_1 = nn.Conv2d(1, 32, 4, 2, 1, bias=False)\n",
    "        self.d2_1 = nn.Conv2d(32, 64, 4, 2, 1, bias=False)\n",
    "        self.d3_1 = nn.Conv2d(64, 128, 4, 2, 1, bias=False)\n",
    "        self.d4_1 = nn.Conv2d(128, 256, 4, 2, 1, bias=False)\n",
    "        #self.d5_1 = nn.Conv2d(256, 512, 4, 2, 1, bias=False)\n",
    "        self.u1 = nn.ConvTranspose2d(512, 256, 8, 2, 3, bias=False)\n",
    "        #self.u2 = nn.ConvTranspose2d(512, 128, 8, 2, 3, bias=False)\n",
    "        self.u2 = nn.ConvTranspose2d(768, 128, 8, 2, 3, bias=False)\n",
    "        #self.u3 = nn.ConvTranspose2d(256, 64, 8, 2, 3, bias=False)\n",
    "        self.u3 = nn.ConvTranspose2d(384, 64, 8, 2, 3, bias=False)\n",
    "        #self.u4 = nn.ConvTranspose2d(128, 32, 8, 2, 3, bias=False)\n",
    "        self.u4 = nn.ConvTranspose2d(192, 32, 8, 2, 3, bias=False)\n",
    "        #self.u5 = nn.ConvTranspose2d(64, 64, 8, 2, 3, bias=False)\n",
    "        self.u5 = nn.ConvTranspose2d(96, 64, 8, 2, 3, bias=False)\n",
    "        self.out = nn.Conv2d(64, 1, 3, 1, 1, bias=False)\n",
    "        self.LeakyRelu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.Relu = nn.ReLU(True)\n",
    "        self.d1Norm = nn.InstanceNorm2d(32)\n",
    "        self.d2Norm = nn.InstanceNorm2d(64)\n",
    "        self.d3Norm = nn.InstanceNorm2d(128)\n",
    "        self.d4Norm = nn.InstanceNorm2d(256)\n",
    "        self.d5Norm = nn.InstanceNorm2d(512)\n",
    "\n",
    "    def forward(self, input):\n",
    "        d1 = self.d1(input)\n",
    "        d1 = self.LeakyRelu(d1)\n",
    "        d1 = self.d1Norm(d1)\n",
    "        \n",
    "        d1_1 = self.d1_1(input)\n",
    "        d1_1 = self.LeakyRelu(d1_1)\n",
    "        d1_1 = self.d1Norm(d1_1)\n",
    "        \n",
    "        d2 = self.d2(d1)\n",
    "        d2 = self.LeakyRelu(d2)\n",
    "        d2 = self.d2Norm(d2)\n",
    "        \n",
    "        d2_1 = self.d2_1(d1_1)\n",
    "        d2_1 = self.LeakyRelu(d2_1)\n",
    "        d2_1 = self.d2Norm(d2_1)\n",
    "        \n",
    "        d3 = self.d3(d2)\n",
    "        d3 = self.LeakyRelu(d3)\n",
    "        d3 = self.d3Norm(d3)\n",
    "        \n",
    "        d3_1 = self.d3_1(d2_1)\n",
    "        d3_1 = self.LeakyRelu(d3_1)\n",
    "        d3_1 = self.d3Norm(d3_1)\n",
    "        \n",
    "        d4 = self.d4(d3)\n",
    "        d4 = self.LeakyRelu(d4)\n",
    "        d4 = self.d4Norm(d4)\n",
    "        \n",
    "        d4_1 = self.d4_1(d3_1)\n",
    "        d4_1 = self.LeakyRelu(d4_1)\n",
    "        d4_1 = self.d4Norm(d4_1)\n",
    "        \n",
    "        d5 = self.d5(d4)\n",
    "        d5 = self.LeakyRelu(d5)\n",
    "        d5 = self.d5Norm(d5)\n",
    "        \n",
    "        u1 = self.u1(d5)\n",
    "        u1 = self.Relu(u1)\n",
    "        u1 = self.d4Norm(u1)\n",
    "        u1 = torch.cat([u1, d4, d4_1],1)\n",
    "        \n",
    "        u2 = self.u2(u1)\n",
    "        u2 = self.Relu(u2)\n",
    "        u2 = self.d3Norm(u2)\n",
    "        u2 = torch.cat([u2, d3, d3_1],1)\n",
    "        \n",
    "        u3 = self.u3(u2)\n",
    "        u3 = self.Relu(u3)\n",
    "        u3 = self.d2Norm(u3)\n",
    "        u3 = torch.cat([u3, d2, d2_1],1)\n",
    "        \n",
    "        u4 = self.u4(u3)\n",
    "        u4 = self.Relu(u4)\n",
    "        u4 = self.d1Norm(u4)\n",
    "        u4 = torch.cat([u4, d1, d1_1],1)\n",
    "        \n",
    "        u5 = self.u5(u4)\n",
    "        output = self.out(u5)\n",
    "        output = torch.tanh(output)\n",
    "        \n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_A_loader,test_A_loader,train_B_loader,test_B_loader = get_data_loader()\n",
    "train_A_loader_iterator = iter(train_A_loader)\n",
    "real_A, _ = train_A_loader_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 256, 256])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = Generator2()\n",
    "top = G(real_A[:,:,:128,:])\n",
    "mid = G(real_A[:,:,64:192,:])\n",
    "bot = G(real_A[:,:,128:256,:])\n",
    "\n",
    "half_img = torch.zeros_like(top)\n",
    "half_img[:,:,:64,:] = (top[:,:,64:,:] + mid[:,:,:64,:])/2\n",
    "half_img[:,:,64:,:] = (bot[:,:,:64,:] + mid[:,:,64:,:])/2\n",
    "\n",
    "img = torch.zeros_like(real_A)\n",
    "img[:,:,:64,:] = top[:,:,:64,:]\n",
    "img[:,:,64:128,:] = half_img[:,:,:64,:]\n",
    "img[:,:,128:192,:] = half_img[:,:,64:,:]\n",
    "img[:,:,192:,:] = bot[:,:,64:,:]\n",
    "\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 256, 256])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = torch.zeros_like(real_A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 8, 2, 3, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(32, 64, 8, 2, 3, bias=False),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # input is 64 x 64\n",
    "            nn.Conv2d(64, 64*2, 8, 2, 3, bias=False),\n",
    "            nn.InstanceNorm2d(64 * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (64) x 32 x 32\n",
    "            nn.Conv2d(64*2, 64 * 4, 8, 2, 3, bias=False),\n",
    "            nn.InstanceNorm2d(64 * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (64*2) x 16 x 16\n",
    "            nn.Conv2d(64*4, 64 * 8, 8, 2, 3, bias=False),\n",
    "            nn.InstanceNorm2d(64 * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(64 * 8, 1, 3, 1, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output\n",
    "        #return output.view(-1, 1).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4, 8])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = Discriminator()\n",
    "pred = D(real_A[:,:,:128,:])\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (main): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(8, 8), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(32, 64, kernel_size=(8, 8), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (3): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(64, 128, kernel_size=(8, 8), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(128, 256, kernel_size=(8, 8), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (9): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): Conv2d(256, 512, kernel_size=(8, 8), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (12): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (13): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (14): Conv2d(512, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (15): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#Create the Generator Network\n",
    "G_AB = Generator2()\n",
    "G_BA = Generator2()\n",
    "#Load Generator Network onto the GPU\n",
    "G_AB.to(device)\n",
    "G_BA.to(device)\n",
    "#Apply weights to the Generator\n",
    "G_AB.apply(weights_init)\n",
    "G_BA.apply(weights_init)\n",
    "#Create the Discriminator Network\n",
    "D_A = Discriminator()\n",
    "D_B = Discriminator()\n",
    "#Load the Disriminator Network onto the GPU\n",
    "D_A.to(device)\n",
    "D_B.to(device)\n",
    "#Apply weights to the Discriminator\n",
    "D_A.apply(weights_init)\n",
    "D_B.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "#Create Optimizers\n",
    "optimizer_G = torch.optim.Adam(itertools.chain(G_AB.parameters(), G_BA.parameters()),\n",
    "                                lr=0.0002, betas=(0.5, 0.999))\n",
    "#Optimizer_G_AB = optim.Adam(G_AB.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "#Optimizer_G_BA = optim.Adam(G_BA.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D_A = optim.Adam(D_A.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D_B = optim.Adam(D_B.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "adversarial_loss = nn.BCELoss()\n",
    "cycle_consis_loss = nn.L1Loss()\n",
    "identity_loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_A_loader,test_A_loader,train_B_loader,test_B_loader = get_data_loader()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fake_A_buffer = ReplayBuffer()\n",
    "fake_B_buffer = ReplayBuffer()\n",
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_cycle = torch.nn.L1Loss()\n",
    "criterion_identity = torch.nn.L1Loss()\n",
    "test_A_loader_iterator = iter(test_A_loader)\n",
    "test_B_loader_iterator = iter(test_B_loader)\n",
    "test_real_A, _ = test_A_loader_iterator.next()\n",
    "test_real_B, _ = test_B_loader_iterator.next()\n",
    "test_real_A = test_real_A.to(device)\n",
    "test_real_B = test_real_B.to(device)\n",
    "for epoch in range(1,20):\n",
    "    train_A_loader_iterator = iter(train_A_loader)\n",
    "    train_B_loader_iterator = iter(train_B_loader)\n",
    "    brake = False\n",
    "    for cnt in range(1000):\n",
    "        target_real = torch.full((1,1,4,8), np.random.uniform(.95,1.05), device=device)\n",
    "        target_fake = torch.full((1,1,4,8), np.random.uniform(-0.05,.05), device=device)\n",
    "        try:\n",
    "            real_A, _ = train_A_loader_iterator.next()\n",
    "            real_B, _ = train_B_loader_iterator.next()\n",
    "            real_A = real_A[:,:,64:192,:]\n",
    "            real_B = real_B[:,:,64:192,:]\n",
    "            real_A = real_A.to(device)\n",
    "            real_B = real_B.to(device)\n",
    "        except:\n",
    "            brake = True\n",
    "            break\n",
    "        ###### Generators A2B and B2A ######\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Identity loss\n",
    "        # G_A2B(B) should equal B if real B is fed\n",
    "        same_B = G_AB(real_B)\n",
    "        loss_identity_B = criterion_identity(same_B, real_B)*10.0\n",
    "        # G_B2A(A) should equal A if real A is fed\n",
    "        same_A = G_BA(real_A)\n",
    "        loss_identity_A = criterion_identity(same_A, real_A)*10.0\n",
    "\n",
    "        # GAN loss\n",
    "        fake_B = G_AB(real_A)\n",
    "        pred_fake = D_B(fake_B)\n",
    "        loss_GAN_A2B = criterion_GAN(pred_fake, target_real)\n",
    "\n",
    "        fake_A = G_BA(real_B)\n",
    "        pred_fake = D_A(fake_A)\n",
    "        loss_GAN_B2A = criterion_GAN(pred_fake, target_real)\n",
    "\n",
    "        # Cycle loss\n",
    "        recovered_A = G_BA(fake_B)\n",
    "        loss_cycle_ABA = criterion_cycle(recovered_A, real_A)*10.0\n",
    "\n",
    "        recovered_B = G_AB(fake_A)\n",
    "        loss_cycle_BAB = criterion_cycle(recovered_B, real_B)*10.0\n",
    "        \n",
    "        #MINE Loss\n",
    "        retAB = torch.mean(real_B) - torch.log(torch.mean(torch.exp(fake_B)))\n",
    "        retBA = torch.mean(real_A) - torch.log(torch.mean(torch.exp(fake_A)))\n",
    "\n",
    "        # Total loss\n",
    "        loss_G = loss_identity_A + loss_identity_B + loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB - retAB - retBA\n",
    "        loss_G.backward()\n",
    "        \n",
    "        optimizer_G.step()\n",
    "        ###################################\n",
    "        for i in range(2):\n",
    "            try:\n",
    "                real_A, _ = train_A_loader_iterator.next()\n",
    "                real_B, _ = train_B_loader_iterator.next()\n",
    "                real_A = real_A[:,:,64:192,:]\n",
    "                real_B = real_B[:,:,64:192,:]\n",
    "                real_A = real_A.to(device)\n",
    "                real_B = real_B.to(device)\n",
    "            except:\n",
    "                brake = True\n",
    "                break\n",
    "            ###### Discriminator A ######\n",
    "            target_real = torch.full((1,1,4,8), np.random.uniform(.95,1.05), device=device)\n",
    "            target_fake = torch.full((1,1,4,8), np.random.uniform(-0.05,.05), device=device)\n",
    "            optimizer_D_A.zero_grad()\n",
    "\n",
    "            # Real loss\n",
    "            pred_real = D_A(real_A)\n",
    "            loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "\n",
    "            # Fake loss\n",
    "            fake_A = fake_A_buffer.push_and_pop(fake_A)\n",
    "            pred_fake = D_A(fake_A.detach())\n",
    "            loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "            # Total loss\n",
    "            loss_D_A = (loss_D_real + loss_D_fake)*0.5\n",
    "            loss_D_A.backward()\n",
    "\n",
    "            optimizer_D_A.step()\n",
    "            ###################################\n",
    "\n",
    "            ###### Discriminator B ######\n",
    "            optimizer_D_B.zero_grad()\n",
    "\n",
    "            # Real loss\n",
    "            pred_real = D_B(real_B)\n",
    "            loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "\n",
    "            # Fake loss\n",
    "            fake_B = fake_B_buffer.push_and_pop(fake_B)\n",
    "            pred_fake = D_B(fake_B.detach())\n",
    "            loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "            # Total loss\n",
    "            loss_D_B = (loss_D_real + loss_D_fake)*0.5\n",
    "            loss_D_B.backward()\n",
    "\n",
    "            optimizer_D_B.step()\n",
    "        ###################################\n",
    "    \n",
    "    torch.save(G_AB.state_dict(), 'C:/Users/ajhon/Desktop/Industrial Math Presentation/us_output_half_imgs/netG_A2B_%d.pth' % epoch)\n",
    "    torch.save(G_BA.state_dict(), 'C:/Users/ajhon/Desktop/Industrial Math Presentation/us_output_half_imgs/netG_B2A_%d.pth' % epoch)\n",
    "    torch.save(D_A.state_dict(), 'C:/Users/ajhon/Desktop/Industrial Math Presentation/us_output_half_imgs/netD_A_%d.pth' % epoch)\n",
    "    torch.save(D_B.state_dict(), 'C:/Users/ajhon/Desktop/Industrial Math Presentation/us_output_half_imgs/netD_B_%d.pth' % epoch)\n",
    "    \n",
    "    fake_imgs_B_top = G_AB(test_real_A[:,:,:128,:])\n",
    "    fake_imgs_B_mid = G_AB(test_real_A[:,:,64:192,:])\n",
    "    fake_imgs_B_bot = G_AB(test_real_A[:,:,128:256,:])\n",
    "    \n",
    "    half_img_B = torch.zeros_like(fake_imgs_B_top)\n",
    "    half_img_B[:,:,:64,:] = (fake_imgs_B_top[:,:,64:,:] + fake_imgs_B_mid[:,:,:64,:])/2\n",
    "    half_img_B[:,:,64:,:] = (fake_imgs_B_bot[:,:,:64,:] + fake_imgs_B_mid[:,:,64:,:])/2\n",
    "    \n",
    "    fake_imgs_B = torch.zeros_like(test_real_A)\n",
    "    fake_imgs_B[:,:,:64,:] = fake_imgs_B_top[:,:,:64,:]\n",
    "    fake_imgs_B[:,:,64:128,:] = half_img_B[:,:,:64,:]\n",
    "    fake_imgs_B[:,:,128:192,:] = half_img_B[:,:,64:,:]\n",
    "    fake_imgs_B[:,:,192:,:] = fake_imgs_B_bot[:,:,64:,:]\n",
    "    \n",
    "    fake_imgs_A_top = G_BA(test_real_B[:,:,:128,:])\n",
    "    fake_imgs_A_mid = G_BA(test_real_B[:,:,64:192,:])\n",
    "    fake_imgs_A_bot = G_BA(test_real_B[:,:,128:256,:])\n",
    "    \n",
    "    half_img_A = torch.zeros_like(fake_imgs_A_top)\n",
    "    half_img_A[:,:,:64,:] = (fake_imgs_A_top[:,:,64:,:] + fake_imgs_A_mid[:,:,:64,:])/2\n",
    "    half_img_A[:,:,64:,:] = (fake_imgs_A_bot[:,:,:64,:] + fake_imgs_A_mid[:,:,64:,:])/2\n",
    "    \n",
    "    fake_imgs_A = torch.zeros_like(test_real_A)\n",
    "    fake_imgs_A[:,:,:64,:] = fake_imgs_A_top[:,:,:64,:]\n",
    "    fake_imgs_A[:,:,64:128,:] = half_img_B[:,:,:64,:]\n",
    "    fake_imgs_A[:,:,128:192,:] = half_img_B[:,:,64:,:]\n",
    "    fake_imgs_A[:,:,192:,:] = fake_imgs_B_bot[:,:,64:,:]\n",
    "    \n",
    "    unorm = UnNormalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "    fake_imgs_B = unorm(fake_imgs_B)\n",
    "    fake_imgs_A = unorm(fake_imgs_A)\n",
    "    save_image(fake_imgs_B.detach().cpu(),'C:/Users/ajhon/Desktop/Industrial Math Presentation/half_test_series/test%d.png' % epoch)\n",
    "    #save_image(fake_imgs_A.detach().cpu(),'C:/Users/ajhon/Desktop/Industrial Math Presentation/Low_freq_256_2/test%d.png' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "    fake_imgs_B_top = G_AB(test_real_A[:,:,:128,:])\n",
    "    fake_imgs_B_mid = G_AB(test_real_A[:,:,64:192,:])\n",
    "    fake_imgs_B_bot = G_AB(test_real_A[:,:,128:256,:])\n",
    "    \n",
    "    half_img_B = torch.zeros_like(fake_imgs_B_top)\n",
    "    half_img_B[:,:,:64,:] = (fake_imgs_B_top[:,:,64:,:] + fake_imgs_B_mid[:,:,:64,:])/2\n",
    "    half_img_B[:,:,64:,:] = (fake_imgs_B_bot[:,:,:64,:] + fake_imgs_B_mid[:,:,64:,:])/2\n",
    "    \n",
    "    fake_imgs_B = torch.zeros_like(test_real_A)\n",
    "    fake_imgs_B[:,:,:64,:] = fake_imgs_B_top[:,:,:64,:]\n",
    "    fake_imgs_B[:,:,64:128,:] = half_img_B[:,:,:64,:]\n",
    "    fake_imgs_B[:,:,128:192,:] = half_img_B[:,:,64:,:]\n",
    "    fake_imgs_B[:,:,192:,:] = fake_imgs_B_bot[:,:,64:,:]\n",
    "    \n",
    "    fake_imgs_A_top = G_BA(test_real_B[:,:,:128,:])\n",
    "    fake_imgs_A_mid = G_BA(test_real_B[:,:,64:192,:])\n",
    "    fake_imgs_A_bot = G_BA(test_real_B[:,:,128:256,:])\n",
    "    \n",
    "    half_img_A = torch.zeros_like(fake_imgs_A_top)\n",
    "    half_img_A[:,:,:64,:] = (fake_imgs_A_top[:,:,64:,:] + fake_imgs_A_mid[:,:,:64,:])/2\n",
    "    half_img_A[:,:,64:,:] = (fake_imgs_A_bot[:,:,:64,:] + fake_imgs_A_mid[:,:,64:,:])/2\n",
    "    \n",
    "    fake_imgs_A = torch.zeros_like(test_real_A)\n",
    "    fake_imgs_A[:,:,:64,:] = fake_imgs_A_top[:,:,:64,:]\n",
    "    fake_imgs_A[:,:,64:128,:] = half_img_B[:,:,:64,:]\n",
    "    fake_imgs_A[:,:,128:192,:] = half_img_B[:,:,64:,:]\n",
    "    fake_imgs_A[:,:,192:,:] = fake_imgs_B_bot[:,:,64:,:]\n",
    "    \n",
    "    unorm = UnNormalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "    fake_imgs_B = unorm(fake_imgs_B)\n",
    "    fake_imgs_A = unorm(fake_imgs_A)\n",
    "    save_image(fake_imgs_B.detach().cpu(),'C:/Users/ajhon/Desktop/Industrial Math Presentation/us_output_half_imgs/test%d.png' % epoch)\n",
    "    #save_image(fake_imgs_A.detach().cpu(),'C:/Users/ajhon/Desktop/Industrial Math Presentation/Low_freq_256_2/test%d.png' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8, 8])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 256, 256])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = Generator2()\n",
    "top = G(real_A[:,:,:128,:])\n",
    "mid = G(real_A[:,:,64:192,:])\n",
    "bot = G(real_A[:,:,128:256,:])\n",
    "\n",
    "half_img = torch.zeros_like(top)\n",
    "half_img[:,:,:64,:] = (top[:,:,64:,:] + mid[:,:,:64,:])/2\n",
    "half_img[:,:,64:,:] = (bot[:,:,:64,:] + mid[:,:,64:,:])/2\n",
    "\n",
    "img = torch.zeros_like(real_A)\n",
    "img[:,:,:64,:] = top[:,:,:64,:]\n",
    "img[:,:,64:128,:] = half_img[:,:,:64,:]\n",
    "img[:,:,128:192,:] = half_img[:,:,64:,:]\n",
    "img[:,:,192:,:] = bot[:,:,64:,:]\n",
    "\n",
    "img.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
